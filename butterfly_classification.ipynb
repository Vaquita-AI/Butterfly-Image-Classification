{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "685eb678",
      "metadata": {
        "id": "685eb678"
      },
      "source": [
        "# 1 Problem Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "k3Jly2kXoA_Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3Jly2kXoA_Z",
        "outputId": "0e0b66ea-f199-4703-d8ca-1dcb1e498b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# path to the link you created\n",
        "path_to_images = '/content/drive/MyDrive/Butterfly Dataset/data/'\n",
        "labels_path = \"/content/drive/MyDrive/Butterfly Dataset/labels.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fcb5209",
      "metadata": {
        "id": "0fcb5209"
      },
      "source": [
        "# 2 Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9781f4cf",
      "metadata": {
        "id": "9781f4cf"
      },
      "source": [
        "# 3 Data Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "53b8b0f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53b8b0f0",
        "outputId": "8eb15b90-e9c6-45c9-d042-d67ee827eba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3899 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the labels\n",
        "labels_df = pd.read_csv(labels_path)\n",
        "model_save_path = '/content/drive/My Drive/butterfly_model_directory_w_Aug/'\n",
        "\n",
        "# Split the data into training+validation and testing sets\n",
        "train_val_df, test_df = train_test_split(\n",
        "    labels_df, test_size=0.2, random_state=7\n",
        ")\n",
        "\n",
        "# Split the training+validation set into training and validation sets\n",
        "train_df, valid_df = train_test_split(\n",
        "    train_val_df, test_size=0.25, random_state=77\n",
        ")\n",
        "\n",
        "# Define the image size and batch size\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "# Initialize the data generators\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create the training, validation, and testing data generators\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=valid_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Use 'categorical' if more than two classes\n",
        "    shuffle=False  # Do not shuffle for evaluation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qO8KcCjv4lGa"
      },
      "id": "qO8KcCjv4lGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the labels\n",
        "labels_df = pd.read_csv(labels_path)\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "train_df, test_df = train_test_split(labels_df, test_size=0.2, random_state=7)\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.25, random_state=77)\n",
        "\n",
        "# Define the image size and batch size\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "# Initialize the data generators with preprocessing function for MobileNetV2\n",
        "# Add data augmentation parameters to the training data generator\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "datagen_valid_test = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Create the data generators\n",
        "train_generator = datagen_train.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = datagen_valid_test.flow_from_dataframe(\n",
        "    dataframe=valid_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = datagen_valid_test.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top of MobileNetV2\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "\n",
        "# Define the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_df.shape[0] // batch_size,\n",
        "    epochs=1,  # Adjust the number of epochs based on your dataset and training time\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=valid_df.shape[0] // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(\n",
        "    test_generator,\n",
        "    steps=np.ceil(test_df.shape[0] / batch_size)\n",
        ")\n",
        "\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwZfUVo24lOf",
        "outputId": "925a1b6b-155e-490b-968f-12cf9c27a6bf"
      },
      "id": "ZwZfUVo24lOf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3899 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121/121 [==============================] - 32s 230ms/step - loss: 1.6364 - accuracy: 0.5953 - val_loss: 0.8812 - val_accuracy: 0.7344\n",
            "41/41 [==============================] - 873s 22s/step - loss: 0.8419 - accuracy: 0.7454\n",
            "Test loss: 0.8419113159179688\n",
            "Test accuracy: 0.7453846335411072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k1tQ0BC8ARQB"
      },
      "id": "k1tQ0BC8ARQB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample of data"
      ],
      "metadata": {
        "id": "m6yGt2OIEZPI"
      },
      "id": "m6yGt2OIEZPI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the labels\n",
        "labels_df_sample = labels_df.sample(n=500, random_state=777)\n",
        "\n",
        "# Ensure that each class has at least one image\n",
        "min_images_per_class = max(labels_df['label'].value_counts().min(), 1)\n",
        "\n",
        "# Create a StratifiedShuffleSplit object\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=500, random_state=777)\n",
        "\n",
        "# Perform the split\n",
        "for train_index, test_index in sss.split(labels_df, labels_df['label']):\n",
        "    labels_df_sample = labels_df.iloc[test_index]\n",
        "\n",
        "# Check if all classes are present\n",
        "assert labels_df_sample['label'].nunique() == labels_df['label'].nunique()\n",
        "\n",
        "# Now, split the sampled data into training+validation and testing sets\n",
        "train_val_df, test_df = train_test_split(labels_df_sample, test_size=0.2, stratify=labels_df_sample['label'], random_state=7)\n",
        "\n",
        "# Split the training+validation set into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_val_df, test_size=0.25, stratify=train_val_df['label'], random_state=77)"
      ],
      "metadata": {
        "id": "fMg0GtkMEYIA"
      },
      "id": "fMg0GtkMEYIA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization, learning rate scheduling, batch normalization, and early stopping (NO AUGMENTATION)"
      ],
      "metadata": {
        "id": "KG8P3KLGARjX"
      },
      "id": "KG8P3KLGARjX"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input  # Import the preprocess_input\n",
        "\n",
        "# Load the labels\n",
        "labels_df = pd.read_csv(labels_path)\n",
        "\n",
        "# Split the data into training+validation and testing sets\n",
        "train_val_df, test_df = train_test_split(labels_df, test_size=0.2, random_state=7)\n",
        "\n",
        "# Split the training+validation set into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_val_df, test_size=0.25, random_state=77)\n",
        "\n",
        "# Define the image size and batch size\n",
        "image_size = (224, 224)  # Updated to match your dataset's resolution\n",
        "batch_size = 32\n",
        "\n",
        "# Initialize the data generators with preprocessing function for MobileNetV2\n",
        "datagen_train = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,  # MobileNetV2's preprocessing\n",
        "    # Add data augmentation parameters here if needed\n",
        ")\n",
        "\n",
        "datagen_valid_test = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Create the data generators\n",
        "train_generator = datagen_train.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = datagen_valid_test.flow_from_dataframe(\n",
        "    dataframe=valid_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = datagen_valid_test.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top of MobileNetV2 with BatchNormalization and Dropout for regularization\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)  # Add BatchNormalization\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Add Dropout\n",
        "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "\n",
        "# Define the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model with a learning rate scheduler\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define EarlyStopping and ReduceLROnPlateau callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, min_lr=1e-6)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    model_save_path + 'model_epoch_{epoch:02d}.h5',  # Save path with epoch number\n",
        "    monitor='val_loss',            # The metric to monitor\n",
        "    save_best_only=False,          # If False, saves the model after every epoch regardless of the metric\n",
        "    save_weights_only=False,       # If True, saves only the weights, else saves the full model\n",
        "    verbose=1                      # Verbosity mode\n",
        ")\n",
        "# Train the model with the new callbacks including ModelCheckpoint\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_df.shape[0] // batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=valid_df.shape[0] // batch_size,\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]  # Add model_checkpoint here\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(\n",
        "    test_generator,\n",
        "    steps=test_df.shape[0] // batch_size\n",
        ")\n",
        "\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUCDMcXQARrR",
        "outputId": "8b579ac6-dd89-494b-a92b-6672f9f459ec"
      },
      "id": "xUCDMcXQARrR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3899 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n",
            "Epoch 1/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 3.8360 - accuracy: 0.1490\n",
            "Epoch 1: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_01.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1323s 11s/step - loss: 3.8360 - accuracy: 0.1490 - val_loss: 2.8023 - val_accuracy: 0.5125 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 2.0577 - accuracy: 0.5045\n",
            "Epoch 2: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_02.h5\n",
            "121/121 [==============================] - 25s 210ms/step - loss: 2.0577 - accuracy: 0.5045 - val_loss: 1.6835 - val_accuracy: 0.6922 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 1.3174 - accuracy: 0.6786\n",
            "Epoch 3: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_03.h5\n",
            "121/121 [==============================] - 26s 216ms/step - loss: 1.3174 - accuracy: 0.6786 - val_loss: 1.1832 - val_accuracy: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.9525 - accuracy: 0.7673\n",
            "Epoch 4: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_04.h5\n",
            "121/121 [==============================] - 30s 246ms/step - loss: 0.9525 - accuracy: 0.7673 - val_loss: 0.9539 - val_accuracy: 0.7617 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.7312 - accuracy: 0.8143\n",
            "Epoch 5: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_05.h5\n",
            "121/121 [==============================] - 27s 221ms/step - loss: 0.7312 - accuracy: 0.8143 - val_loss: 0.8226 - val_accuracy: 0.7867 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.8632\n",
            "Epoch 6: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_06.h5\n",
            "121/121 [==============================] - 26s 214ms/step - loss: 0.5783 - accuracy: 0.8632 - val_loss: 0.7499 - val_accuracy: 0.8055 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.4715 - accuracy: 0.8888\n",
            "Epoch 7: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_07.h5\n",
            "121/121 [==============================] - 30s 247ms/step - loss: 0.4715 - accuracy: 0.8888 - val_loss: 0.6900 - val_accuracy: 0.8133 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.4121 - accuracy: 0.8976\n",
            "Epoch 8: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_08.h5\n",
            "121/121 [==============================] - 31s 253ms/step - loss: 0.4121 - accuracy: 0.8976 - val_loss: 0.6436 - val_accuracy: 0.8273 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.9204\n",
            "Epoch 9: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_09.h5\n",
            "121/121 [==============================] - 31s 254ms/step - loss: 0.3522 - accuracy: 0.9204 - val_loss: 0.6175 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.9291\n",
            "Epoch 10: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_10.h5\n",
            "121/121 [==============================] - 30s 250ms/step - loss: 0.2991 - accuracy: 0.9291 - val_loss: 0.6074 - val_accuracy: 0.8234 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.9439\n",
            "Epoch 11: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_11.h5\n",
            "121/121 [==============================] - 26s 214ms/step - loss: 0.2538 - accuracy: 0.9439 - val_loss: 0.5879 - val_accuracy: 0.8297 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9514\n",
            "Epoch 12: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_12.h5\n",
            "121/121 [==============================] - 31s 255ms/step - loss: 0.2200 - accuracy: 0.9514 - val_loss: 0.5805 - val_accuracy: 0.8305 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9607\n",
            "Epoch 13: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_13.h5\n",
            "121/121 [==============================] - 30s 250ms/step - loss: 0.1919 - accuracy: 0.9607 - val_loss: 0.5579 - val_accuracy: 0.8391 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.9656\n",
            "Epoch 14: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_14.h5\n",
            "121/121 [==============================] - 30s 245ms/step - loss: 0.1746 - accuracy: 0.9656 - val_loss: 0.5618 - val_accuracy: 0.8328 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9705\n",
            "Epoch 15: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_15.h5\n",
            "121/121 [==============================] - 29s 244ms/step - loss: 0.1535 - accuracy: 0.9705 - val_loss: 0.5369 - val_accuracy: 0.8469 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9700\n",
            "Epoch 16: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_16.h5\n",
            "121/121 [==============================] - 26s 218ms/step - loss: 0.1364 - accuracy: 0.9700 - val_loss: 0.5358 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9736\n",
            "Epoch 17: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_17.h5\n",
            "121/121 [==============================] - 30s 246ms/step - loss: 0.1283 - accuracy: 0.9736 - val_loss: 0.5305 - val_accuracy: 0.8492 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.9832\n",
            "Epoch 18: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_18.h5\n",
            "121/121 [==============================] - 30s 248ms/step - loss: 0.1043 - accuracy: 0.9832 - val_loss: 0.5212 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9788\n",
            "Epoch 19: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_19.h5\n",
            "121/121 [==============================] - 29s 244ms/step - loss: 0.1013 - accuracy: 0.9788 - val_loss: 0.5120 - val_accuracy: 0.8508 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9886\n",
            "Epoch 20: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_20.h5\n",
            "121/121 [==============================] - 26s 218ms/step - loss: 0.0822 - accuracy: 0.9886 - val_loss: 0.5140 - val_accuracy: 0.8492 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9858\n",
            "Epoch 21: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_21.h5\n",
            "121/121 [==============================] - 30s 251ms/step - loss: 0.0844 - accuracy: 0.9858 - val_loss: 0.5133 - val_accuracy: 0.8461 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9876\n",
            "Epoch 22: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_22.h5\n",
            "121/121 [==============================] - 25s 210ms/step - loss: 0.0802 - accuracy: 0.9876 - val_loss: 0.4948 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9907\n",
            "Epoch 23: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_23.h5\n",
            "121/121 [==============================] - 31s 254ms/step - loss: 0.0689 - accuracy: 0.9907 - val_loss: 0.5053 - val_accuracy: 0.8539 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9922\n",
            "Epoch 24: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_24.h5\n",
            "121/121 [==============================] - 27s 223ms/step - loss: 0.0631 - accuracy: 0.9922 - val_loss: 0.5016 - val_accuracy: 0.8586 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9922\n",
            "Epoch 25: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_25.h5\n",
            "121/121 [==============================] - 26s 216ms/step - loss: 0.0552 - accuracy: 0.9922 - val_loss: 0.4878 - val_accuracy: 0.8562 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9907\n",
            "Epoch 26: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_26.h5\n",
            "121/121 [==============================] - 26s 214ms/step - loss: 0.0580 - accuracy: 0.9907 - val_loss: 0.4968 - val_accuracy: 0.8602 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9941\n",
            "Epoch 27: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_27.h5\n",
            "121/121 [==============================] - 25s 207ms/step - loss: 0.0506 - accuracy: 0.9941 - val_loss: 0.4856 - val_accuracy: 0.8609 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9941\n",
            "Epoch 28: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_28.h5\n",
            "121/121 [==============================] - 27s 220ms/step - loss: 0.0486 - accuracy: 0.9941 - val_loss: 0.4940 - val_accuracy: 0.8562 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9951\n",
            "Epoch 29: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_29.h5\n",
            "121/121 [==============================] - 26s 216ms/step - loss: 0.0434 - accuracy: 0.9951 - val_loss: 0.4980 - val_accuracy: 0.8562 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9972\n",
            "Epoch 30: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_30.h5\n",
            "121/121 [==============================] - 26s 214ms/step - loss: 0.0360 - accuracy: 0.9972 - val_loss: 0.4804 - val_accuracy: 0.8617 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9948\n",
            "Epoch 31: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_31.h5\n",
            "121/121 [==============================] - 26s 213ms/step - loss: 0.0351 - accuracy: 0.9948 - val_loss: 0.4925 - val_accuracy: 0.8664 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9953\n",
            "Epoch 32: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_32.h5\n",
            "121/121 [==============================] - 31s 254ms/step - loss: 0.0359 - accuracy: 0.9953 - val_loss: 0.4941 - val_accuracy: 0.8609 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9977\n",
            "Epoch 33: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_33.h5\n",
            "121/121 [==============================] - 30s 246ms/step - loss: 0.0313 - accuracy: 0.9977 - val_loss: 0.4938 - val_accuracy: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9966\n",
            "Epoch 34: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_34.h5\n",
            "121/121 [==============================] - 26s 216ms/step - loss: 0.0314 - accuracy: 0.9966 - val_loss: 0.4912 - val_accuracy: 0.8680 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9977\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\n",
            "Epoch 35: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_35.h5\n",
            "121/121 [==============================] - 29s 244ms/step - loss: 0.0267 - accuracy: 0.9977 - val_loss: 0.4821 - val_accuracy: 0.8602 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9969\n",
            "Epoch 36: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_36.h5\n",
            "121/121 [==============================] - 30s 246ms/step - loss: 0.0258 - accuracy: 0.9969 - val_loss: 0.4718 - val_accuracy: 0.8680 - lr: 2.0000e-05\n",
            "Epoch 37/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9990\n",
            "Epoch 37: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_37.h5\n",
            "121/121 [==============================] - 26s 216ms/step - loss: 0.0227 - accuracy: 0.9990 - val_loss: 0.4752 - val_accuracy: 0.8664 - lr: 2.0000e-05\n",
            "Epoch 38/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9984\n",
            "Epoch 38: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_38.h5\n",
            "121/121 [==============================] - 26s 214ms/step - loss: 0.0243 - accuracy: 0.9984 - val_loss: 0.4811 - val_accuracy: 0.8672 - lr: 2.0000e-05\n",
            "Epoch 39/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9974\n",
            "Epoch 39: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_39.h5\n",
            "121/121 [==============================] - 25s 208ms/step - loss: 0.0242 - accuracy: 0.9974 - val_loss: 0.4885 - val_accuracy: 0.8672 - lr: 2.0000e-05\n",
            "Epoch 40/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9982\n",
            "Epoch 40: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_40.h5\n",
            "121/121 [==============================] - 29s 241ms/step - loss: 0.0223 - accuracy: 0.9982 - val_loss: 0.4819 - val_accuracy: 0.8664 - lr: 2.0000e-05\n",
            "Epoch 41/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9977\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\n",
            "Epoch 41: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_41.h5\n",
            "121/121 [==============================] - 26s 211ms/step - loss: 0.0253 - accuracy: 0.9977 - val_loss: 0.4859 - val_accuracy: 0.8680 - lr: 2.0000e-05\n",
            "Epoch 42/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9987\n",
            "Epoch 42: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_42.h5\n",
            "121/121 [==============================] - 25s 210ms/step - loss: 0.0220 - accuracy: 0.9987 - val_loss: 0.4860 - val_accuracy: 0.8672 - lr: 4.0000e-06\n",
            "Epoch 43/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9984\n",
            "Epoch 43: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_43.h5\n",
            "121/121 [==============================] - 25s 209ms/step - loss: 0.0215 - accuracy: 0.9984 - val_loss: 0.4698 - val_accuracy: 0.8687 - lr: 4.0000e-06\n",
            "Epoch 44/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9987\n",
            "Epoch 44: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_44.h5\n",
            "121/121 [==============================] - 26s 211ms/step - loss: 0.0227 - accuracy: 0.9987 - val_loss: 0.4868 - val_accuracy: 0.8656 - lr: 4.0000e-06\n",
            "Epoch 45/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9984\n",
            "Epoch 45: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_45.h5\n",
            "121/121 [==============================] - 29s 240ms/step - loss: 0.0196 - accuracy: 0.9984 - val_loss: 0.4758 - val_accuracy: 0.8680 - lr: 4.0000e-06\n",
            "Epoch 46/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9982\n",
            "Epoch 46: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_46.h5\n",
            "121/121 [==============================] - 26s 216ms/step - loss: 0.0237 - accuracy: 0.9982 - val_loss: 0.4880 - val_accuracy: 0.8648 - lr: 4.0000e-06\n",
            "Epoch 47/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9982\n",
            "Epoch 47: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_47.h5\n",
            "121/121 [==============================] - 26s 211ms/step - loss: 0.0215 - accuracy: 0.9982 - val_loss: 0.4789 - val_accuracy: 0.8664 - lr: 4.0000e-06\n",
            "Epoch 48/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9979\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 48: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_48.h5\n",
            "121/121 [==============================] - 26s 218ms/step - loss: 0.0207 - accuracy: 0.9979 - val_loss: 0.4881 - val_accuracy: 0.8664 - lr: 4.0000e-06\n",
            "Epoch 49/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9990\n",
            "Epoch 49: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_49.h5\n",
            "121/121 [==============================] - 29s 242ms/step - loss: 0.0205 - accuracy: 0.9990 - val_loss: 0.4790 - val_accuracy: 0.8687 - lr: 1.0000e-06\n",
            "Epoch 50/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9979\n",
            "Epoch 50: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_50.h5\n",
            "121/121 [==============================] - 26s 218ms/step - loss: 0.0223 - accuracy: 0.9979 - val_loss: 0.4838 - val_accuracy: 0.8687 - lr: 1.0000e-06\n",
            "Epoch 51/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9972\n",
            "Epoch 51: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_51.h5\n",
            "121/121 [==============================] - 29s 243ms/step - loss: 0.0237 - accuracy: 0.9972 - val_loss: 0.4842 - val_accuracy: 0.8664 - lr: 1.0000e-06\n",
            "Epoch 52/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9979\n",
            "Epoch 52: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_52.h5\n",
            "121/121 [==============================] - 26s 211ms/step - loss: 0.0210 - accuracy: 0.9979 - val_loss: 0.4773 - val_accuracy: 0.8680 - lr: 1.0000e-06\n",
            "Epoch 53/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9992Restoring model weights from the end of the best epoch: 43.\n",
            "\n",
            "Epoch 53: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_53.h5\n",
            "121/121 [==============================] - 25s 209ms/step - loss: 0.0202 - accuracy: 0.9992 - val_loss: 0.4837 - val_accuracy: 0.8664 - lr: 1.0000e-06\n",
            "Epoch 53: early stopping\n",
            "40/40 [==============================] - 415s 11s/step - loss: 0.4376 - accuracy: 0.8813\n",
            "Test loss: 0.43759170174598694\n",
            "Test accuracy: 0.8812500238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same as before WITH AUGMENTATION"
      ],
      "metadata": {
        "id": "0gxwRlZZRFDb"
      },
      "id": "0gxwRlZZRFDb"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input  # Import the preprocess_input\n",
        "\n",
        "# Load the labels\n",
        "labels_df = pd.read_csv(labels_path)\n",
        "\n",
        "# Split the data into training+validation and testing sets\n",
        "train_val_df, test_df = train_test_split(labels_df, test_size=0.2, random_state=7)\n",
        "\n",
        "# Split the training+validation set into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_val_df, test_size=0.25, random_state=77)\n",
        "\n",
        "# Define the image size and batch size\n",
        "image_size = (224, 224)  # Updated to match your dataset's resolution\n",
        "batch_size = 32\n",
        "\n",
        "# Initialize the data generators with preprocessing function for MobileNetV2\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "datagen_valid_test = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Create the data generators\n",
        "train_generator = datagen_train.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = datagen_valid_test.flow_from_dataframe(\n",
        "    dataframe=valid_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = datagen_valid_test.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=path_to_images,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top of MobileNetV2 with BatchNormalization and Dropout for regularization\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)  # Add BatchNormalization\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Add Dropout\n",
        "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "\n",
        "# Define the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model with a learning rate scheduler\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define EarlyStopping and ReduceLROnPlateau callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, min_lr=1e-6)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    model_save_path + 'model_epoch_{epoch:02d}.h5',  # Save path with epoch number\n",
        "    monitor='val_loss',            # The metric to monitor\n",
        "    save_best_only=False,          # If False, saves the model after every epoch regardless of the metric\n",
        "    save_weights_only=False,       # If True, saves only the weights, else saves the full model\n",
        "    verbose=1                      # Verbosity mode\n",
        ")\n",
        "# Train the model with the new callbacks including ModelCheckpoint\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_df.shape[0] // batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=valid_df.shape[0] // batch_size,\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]  # Add model_checkpoint here\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(\n",
        "    test_generator,\n",
        "    steps=test_df.shape[0] // batch_size\n",
        ")\n",
        "\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "GGFP-5akRKaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0568acad-8bcb-48ec-c985-287defb1fa06"
      },
      "id": "GGFP-5akRKaS",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3899 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n",
            "Found 1300 validated image filenames belonging to 75 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 3.9622 - accuracy: 0.1265\n",
            "Epoch 1: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_01.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1522s 13s/step - loss: 3.9622 - accuracy: 0.1265 - val_loss: 2.8969 - val_accuracy: 0.4734 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 2.3724 - accuracy: 0.4213\n",
            "Epoch 2: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_02.h5\n",
            "121/121 [==============================] - 76s 630ms/step - loss: 2.3724 - accuracy: 0.4213 - val_loss: 1.8197 - val_accuracy: 0.6492 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 1.6992 - accuracy: 0.5834\n",
            "Epoch 3: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_03.h5\n",
            "121/121 [==============================] - 82s 672ms/step - loss: 1.6992 - accuracy: 0.5834 - val_loss: 1.2810 - val_accuracy: 0.7305 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 1.3371 - accuracy: 0.6504\n",
            "Epoch 4: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_04.h5\n",
            "121/121 [==============================] - 76s 629ms/step - loss: 1.3371 - accuracy: 0.6504 - val_loss: 1.0175 - val_accuracy: 0.7664 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 1.1145 - accuracy: 0.7062\n",
            "Epoch 5: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_05.h5\n",
            "121/121 [==============================] - 76s 630ms/step - loss: 1.1145 - accuracy: 0.7062 - val_loss: 0.8690 - val_accuracy: 0.7898 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.9544 - accuracy: 0.7406\n",
            "Epoch 6: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_06.h5\n",
            "121/121 [==============================] - 76s 627ms/step - loss: 0.9544 - accuracy: 0.7406 - val_loss: 0.7820 - val_accuracy: 0.8023 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.8470 - accuracy: 0.7680\n",
            "Epoch 7: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_07.h5\n",
            "121/121 [==============================] - 81s 668ms/step - loss: 0.8470 - accuracy: 0.7680 - val_loss: 0.7157 - val_accuracy: 0.8219 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.7908\n",
            "Epoch 8: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_08.h5\n",
            "121/121 [==============================] - 80s 660ms/step - loss: 0.7608 - accuracy: 0.7908 - val_loss: 0.6673 - val_accuracy: 0.8203 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.7980\n",
            "Epoch 9: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_09.h5\n",
            "121/121 [==============================] - 75s 624ms/step - loss: 0.7085 - accuracy: 0.7980 - val_loss: 0.6365 - val_accuracy: 0.8266 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.8254\n",
            "Epoch 10: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_10.h5\n",
            "121/121 [==============================] - 76s 629ms/step - loss: 0.6276 - accuracy: 0.8254 - val_loss: 0.6045 - val_accuracy: 0.8328 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.8311\n",
            "Epoch 11: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_11.h5\n",
            "121/121 [==============================] - 77s 634ms/step - loss: 0.5935 - accuracy: 0.8311 - val_loss: 0.5795 - val_accuracy: 0.8406 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.5560 - accuracy: 0.8435\n",
            "Epoch 12: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_12.h5\n",
            "121/121 [==============================] - 81s 672ms/step - loss: 0.5560 - accuracy: 0.8435 - val_loss: 0.5632 - val_accuracy: 0.8445 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.8477\n",
            "Epoch 13: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_13.h5\n",
            "121/121 [==============================] - 82s 679ms/step - loss: 0.5347 - accuracy: 0.8477 - val_loss: 0.5404 - val_accuracy: 0.8398 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.8562\n",
            "Epoch 14: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_14.h5\n",
            "121/121 [==============================] - 81s 667ms/step - loss: 0.4959 - accuracy: 0.8562 - val_loss: 0.5290 - val_accuracy: 0.8492 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.8684\n",
            "Epoch 15: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_15.h5\n",
            "121/121 [==============================] - 83s 689ms/step - loss: 0.4645 - accuracy: 0.8684 - val_loss: 0.5292 - val_accuracy: 0.8523 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.8673\n",
            "Epoch 16: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_16.h5\n",
            "121/121 [==============================] - 81s 667ms/step - loss: 0.4444 - accuracy: 0.8673 - val_loss: 0.5122 - val_accuracy: 0.8469 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8779\n",
            "Epoch 17: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_17.h5\n",
            "121/121 [==============================] - 81s 668ms/step - loss: 0.4279 - accuracy: 0.8779 - val_loss: 0.5045 - val_accuracy: 0.8578 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8805\n",
            "Epoch 18: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_18.h5\n",
            "121/121 [==============================] - 80s 664ms/step - loss: 0.4050 - accuracy: 0.8805 - val_loss: 0.4923 - val_accuracy: 0.8547 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8878\n",
            "Epoch 19: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_19.h5\n",
            "121/121 [==============================] - 81s 666ms/step - loss: 0.3814 - accuracy: 0.8878 - val_loss: 0.4970 - val_accuracy: 0.8523 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.8849\n",
            "Epoch 20: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_20.h5\n",
            "121/121 [==============================] - 78s 644ms/step - loss: 0.3701 - accuracy: 0.8849 - val_loss: 0.4896 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.8878\n",
            "Epoch 21: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_21.h5\n",
            "121/121 [==============================] - 78s 644ms/step - loss: 0.3670 - accuracy: 0.8878 - val_loss: 0.4767 - val_accuracy: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8958\n",
            "Epoch 22: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_22.h5\n",
            "121/121 [==============================] - 82s 682ms/step - loss: 0.3389 - accuracy: 0.8958 - val_loss: 0.4728 - val_accuracy: 0.8578 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.9033\n",
            "Epoch 23: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_23.h5\n",
            "121/121 [==============================] - 81s 669ms/step - loss: 0.3255 - accuracy: 0.9033 - val_loss: 0.4685 - val_accuracy: 0.8555 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.9025\n",
            "Epoch 24: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_24.h5\n",
            "121/121 [==============================] - 81s 668ms/step - loss: 0.3232 - accuracy: 0.9025 - val_loss: 0.4657 - val_accuracy: 0.8570 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.9054\n",
            "Epoch 25: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_25.h5\n",
            "121/121 [==============================] - 77s 635ms/step - loss: 0.3027 - accuracy: 0.9054 - val_loss: 0.4649 - val_accuracy: 0.8633 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2901 - accuracy: 0.9141\n",
            "Epoch 26: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_26.h5\n",
            "121/121 [==============================] - 77s 638ms/step - loss: 0.2901 - accuracy: 0.9141 - val_loss: 0.4617 - val_accuracy: 0.8602 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.9144\n",
            "Epoch 27: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_27.h5\n",
            "121/121 [==============================] - 77s 640ms/step - loss: 0.2737 - accuracy: 0.9144 - val_loss: 0.4482 - val_accuracy: 0.8633 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2792 - accuracy: 0.9216\n",
            "Epoch 28: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_28.h5\n",
            "121/121 [==============================] - 81s 668ms/step - loss: 0.2792 - accuracy: 0.9216 - val_loss: 0.4587 - val_accuracy: 0.8609 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.9185\n",
            "Epoch 29: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_29.h5\n",
            "121/121 [==============================] - 81s 673ms/step - loss: 0.2660 - accuracy: 0.9185 - val_loss: 0.4383 - val_accuracy: 0.8633 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.9266\n",
            "Epoch 30: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_30.h5\n",
            "121/121 [==============================] - 77s 635ms/step - loss: 0.2470 - accuracy: 0.9266 - val_loss: 0.4370 - val_accuracy: 0.8641 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9263\n",
            "Epoch 31: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_31.h5\n",
            "121/121 [==============================] - 76s 630ms/step - loss: 0.2390 - accuracy: 0.9263 - val_loss: 0.4319 - val_accuracy: 0.8687 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9348\n",
            "Epoch 32: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_32.h5\n",
            "121/121 [==============================] - 81s 667ms/step - loss: 0.2274 - accuracy: 0.9348 - val_loss: 0.4435 - val_accuracy: 0.8672 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.9343\n",
            "Epoch 33: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_33.h5\n",
            "121/121 [==============================] - 76s 633ms/step - loss: 0.2283 - accuracy: 0.9343 - val_loss: 0.4374 - val_accuracy: 0.8687 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.9312\n",
            "Epoch 34: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_34.h5\n",
            "121/121 [==============================] - 80s 663ms/step - loss: 0.2245 - accuracy: 0.9312 - val_loss: 0.4436 - val_accuracy: 0.8656 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9374\n",
            "Epoch 35: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_35.h5\n",
            "121/121 [==============================] - 79s 654ms/step - loss: 0.2109 - accuracy: 0.9374 - val_loss: 0.4404 - val_accuracy: 0.8703 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9338\n",
            "Epoch 36: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_36.h5\n",
            "121/121 [==============================] - 76s 625ms/step - loss: 0.2122 - accuracy: 0.9338 - val_loss: 0.4266 - val_accuracy: 0.8727 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9390\n",
            "Epoch 37: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_37.h5\n",
            "121/121 [==============================] - 80s 665ms/step - loss: 0.2039 - accuracy: 0.9390 - val_loss: 0.4428 - val_accuracy: 0.8680 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9385\n",
            "Epoch 38: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_38.h5\n",
            "121/121 [==============================] - 80s 662ms/step - loss: 0.2027 - accuracy: 0.9385 - val_loss: 0.4427 - val_accuracy: 0.8633 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9460\n",
            "Epoch 39: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_39.h5\n",
            "121/121 [==============================] - 80s 664ms/step - loss: 0.1766 - accuracy: 0.9460 - val_loss: 0.4225 - val_accuracy: 0.8719 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.9426\n",
            "Epoch 40: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_40.h5\n",
            "121/121 [==============================] - 80s 663ms/step - loss: 0.1981 - accuracy: 0.9426 - val_loss: 0.4348 - val_accuracy: 0.8719 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9423\n",
            "Epoch 41: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_41.h5\n",
            "121/121 [==============================] - 80s 656ms/step - loss: 0.1903 - accuracy: 0.9423 - val_loss: 0.4331 - val_accuracy: 0.8781 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9431\n",
            "Epoch 42: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_42.h5\n",
            "121/121 [==============================] - 81s 666ms/step - loss: 0.1774 - accuracy: 0.9431 - val_loss: 0.4287 - val_accuracy: 0.8766 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9452\n",
            "Epoch 43: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_43.h5\n",
            "121/121 [==============================] - 81s 668ms/step - loss: 0.1691 - accuracy: 0.9452 - val_loss: 0.4253 - val_accuracy: 0.8742 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9426\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\n",
            "Epoch 44: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_44.h5\n",
            "121/121 [==============================] - 81s 670ms/step - loss: 0.1750 - accuracy: 0.9426 - val_loss: 0.4327 - val_accuracy: 0.8719 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9516\n",
            "Epoch 45: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_45.h5\n",
            "121/121 [==============================] - 82s 674ms/step - loss: 0.1600 - accuracy: 0.9516 - val_loss: 0.4296 - val_accuracy: 0.8727 - lr: 2.0000e-05\n",
            "Epoch 46/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9514\n",
            "Epoch 46: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_46.h5\n",
            "121/121 [==============================] - 81s 668ms/step - loss: 0.1569 - accuracy: 0.9514 - val_loss: 0.4312 - val_accuracy: 0.8719 - lr: 2.0000e-05\n",
            "Epoch 47/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9498\n",
            "Epoch 47: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_47.h5\n",
            "121/121 [==============================] - 77s 635ms/step - loss: 0.1630 - accuracy: 0.9498 - val_loss: 0.4216 - val_accuracy: 0.8734 - lr: 2.0000e-05\n",
            "Epoch 48/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9503\n",
            "Epoch 48: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_48.h5\n",
            "121/121 [==============================] - 76s 630ms/step - loss: 0.1593 - accuracy: 0.9503 - val_loss: 0.4204 - val_accuracy: 0.8758 - lr: 2.0000e-05\n",
            "Epoch 49/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9558\n",
            "Epoch 49: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_49.h5\n",
            "121/121 [==============================] - 77s 633ms/step - loss: 0.1501 - accuracy: 0.9558 - val_loss: 0.4211 - val_accuracy: 0.8734 - lr: 2.0000e-05\n",
            "Epoch 50/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9475\n",
            "Epoch 50: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_50.h5\n",
            "121/121 [==============================] - 80s 666ms/step - loss: 0.1619 - accuracy: 0.9475 - val_loss: 0.4182 - val_accuracy: 0.8781 - lr: 2.0000e-05\n",
            "Epoch 51/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9535\n",
            "Epoch 51: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_51.h5\n",
            "121/121 [==============================] - 81s 667ms/step - loss: 0.1501 - accuracy: 0.9535 - val_loss: 0.4233 - val_accuracy: 0.8758 - lr: 2.0000e-05\n",
            "Epoch 52/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9529\n",
            "Epoch 52: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_52.h5\n",
            "121/121 [==============================] - 80s 664ms/step - loss: 0.1478 - accuracy: 0.9529 - val_loss: 0.4080 - val_accuracy: 0.8758 - lr: 2.0000e-05\n",
            "Epoch 53/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9547\n",
            "Epoch 53: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_53.h5\n",
            "121/121 [==============================] - 80s 665ms/step - loss: 0.1510 - accuracy: 0.9547 - val_loss: 0.4116 - val_accuracy: 0.8789 - lr: 2.0000e-05\n",
            "Epoch 54/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9529\n",
            "Epoch 54: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_54.h5\n",
            "121/121 [==============================] - 76s 626ms/step - loss: 0.1501 - accuracy: 0.9529 - val_loss: 0.4167 - val_accuracy: 0.8734 - lr: 2.0000e-05\n",
            "Epoch 55/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9573\n",
            "Epoch 55: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_55.h5\n",
            "121/121 [==============================] - 76s 626ms/step - loss: 0.1469 - accuracy: 0.9573 - val_loss: 0.4204 - val_accuracy: 0.8742 - lr: 2.0000e-05\n",
            "Epoch 56/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9560\n",
            "Epoch 56: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_56.h5\n",
            "121/121 [==============================] - 75s 624ms/step - loss: 0.1510 - accuracy: 0.9560 - val_loss: 0.4140 - val_accuracy: 0.8766 - lr: 2.0000e-05\n",
            "Epoch 57/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9514\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\n",
            "Epoch 57: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_57.h5\n",
            "121/121 [==============================] - 76s 626ms/step - loss: 0.1537 - accuracy: 0.9514 - val_loss: 0.4142 - val_accuracy: 0.8711 - lr: 2.0000e-05\n",
            "Epoch 58/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9591\n",
            "Epoch 58: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_58.h5\n",
            "121/121 [==============================] - 76s 629ms/step - loss: 0.1384 - accuracy: 0.9591 - val_loss: 0.4058 - val_accuracy: 0.8758 - lr: 4.0000e-06\n",
            "Epoch 59/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9581\n",
            "Epoch 59: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_59.h5\n",
            "121/121 [==============================] - 80s 662ms/step - loss: 0.1405 - accuracy: 0.9581 - val_loss: 0.4159 - val_accuracy: 0.8711 - lr: 4.0000e-06\n",
            "Epoch 60/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9535\n",
            "Epoch 60: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_60.h5\n",
            "121/121 [==============================] - 79s 657ms/step - loss: 0.1474 - accuracy: 0.9535 - val_loss: 0.4068 - val_accuracy: 0.8742 - lr: 4.0000e-06\n",
            "Epoch 61/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9537\n",
            "Epoch 61: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_61.h5\n",
            "121/121 [==============================] - 80s 661ms/step - loss: 0.1469 - accuracy: 0.9537 - val_loss: 0.4113 - val_accuracy: 0.8742 - lr: 4.0000e-06\n",
            "Epoch 62/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9503\n",
            "Epoch 62: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_62.h5\n",
            "121/121 [==============================] - 80s 659ms/step - loss: 0.1536 - accuracy: 0.9503 - val_loss: 0.4034 - val_accuracy: 0.8727 - lr: 4.0000e-06\n",
            "Epoch 63/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9516\n",
            "Epoch 63: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_63.h5\n",
            "121/121 [==============================] - 76s 630ms/step - loss: 0.1570 - accuracy: 0.9516 - val_loss: 0.4141 - val_accuracy: 0.8711 - lr: 4.0000e-06\n",
            "Epoch 64/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9550\n",
            "Epoch 64: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_64.h5\n",
            "121/121 [==============================] - 80s 662ms/step - loss: 0.1469 - accuracy: 0.9550 - val_loss: 0.4129 - val_accuracy: 0.8727 - lr: 4.0000e-06\n",
            "Epoch 65/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9602\n",
            "Epoch 65: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_65.h5\n",
            "121/121 [==============================] - 81s 671ms/step - loss: 0.1346 - accuracy: 0.9602 - val_loss: 0.4097 - val_accuracy: 0.8742 - lr: 4.0000e-06\n",
            "Epoch 66/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9540\n",
            "Epoch 66: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_66.h5\n",
            "121/121 [==============================] - 76s 628ms/step - loss: 0.1443 - accuracy: 0.9540 - val_loss: 0.4126 - val_accuracy: 0.8750 - lr: 4.0000e-06\n",
            "Epoch 67/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.9563\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 67: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_67.h5\n",
            "121/121 [==============================] - 81s 673ms/step - loss: 0.1436 - accuracy: 0.9563 - val_loss: 0.4136 - val_accuracy: 0.8742 - lr: 4.0000e-06\n",
            "Epoch 68/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9604\n",
            "Epoch 68: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_68.h5\n",
            "121/121 [==============================] - 75s 621ms/step - loss: 0.1329 - accuracy: 0.9604 - val_loss: 0.4124 - val_accuracy: 0.8742 - lr: 1.0000e-06\n",
            "Epoch 69/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9563\n",
            "Epoch 69: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_69.h5\n",
            "121/121 [==============================] - 78s 643ms/step - loss: 0.1401 - accuracy: 0.9563 - val_loss: 0.4135 - val_accuracy: 0.8742 - lr: 1.0000e-06\n",
            "Epoch 70/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9529\n",
            "Epoch 70: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_70.h5\n",
            "121/121 [==============================] - 76s 626ms/step - loss: 0.1505 - accuracy: 0.9529 - val_loss: 0.4141 - val_accuracy: 0.8758 - lr: 1.0000e-06\n",
            "Epoch 71/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9563\n",
            "Epoch 71: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_71.h5\n",
            "121/121 [==============================] - 76s 627ms/step - loss: 0.1464 - accuracy: 0.9563 - val_loss: 0.4118 - val_accuracy: 0.8766 - lr: 1.0000e-06\n",
            "Epoch 72/100\n",
            "121/121 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9540Restoring model weights from the end of the best epoch: 62.\n",
            "\n",
            "Epoch 72: saving model to /content/drive/My Drive/butterfly_model_directory/model_epoch_72.h5\n",
            "121/121 [==============================] - 79s 655ms/step - loss: 0.1553 - accuracy: 0.9540 - val_loss: 0.4159 - val_accuracy: 0.8750 - lr: 1.0000e-06\n",
            "Epoch 72: early stopping\n",
            "40/40 [==============================] - 333s 9s/step - loss: 0.3698 - accuracy: 0.9062\n",
            "Test loss: 0.3697872459888458\n",
            "Test accuracy: 0.90625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "119cac83",
      "metadata": {
        "id": "119cac83"
      },
      "source": [
        "# 4 Choosing a Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "568728e2",
      "metadata": {
        "id": "568728e2"
      },
      "source": [
        "# 5 Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56362a3a",
      "metadata": {
        "id": "56362a3a"
      },
      "source": [
        "# 6 Evaluating the Model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
